{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cfb5fc-8a50-4599-a84e-af1521fede73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f950dec-8436-4209-97bd-dfbaf5d03245",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"data\", train=True, transform=ToTensor(), download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\", train=False, transform=ToTensor(), download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b922e737-8be2-4630-b0a2-8241cd7c37df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5978ec63-f77c-403e-b0ec-712f871a79b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0627857c-8a8f-473c-a758-82ea471599ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a89a9d0-cdd8-4b4e-88ab-b4a8c3716f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    \"train\": DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
    "    \"test\": DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07b36a1a-9932-42fd-9a0f-06f85c43ada9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x762c34c9f380>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x762d4837e490>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ade61b0-865d-4c88-9f35-f2ea5cda8f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f36db54-be1d-4b7d-bbcd-cf6de5944e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff557ff3-0e59-47bd-9a85-7283925e1608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders[\"train\"]):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(\n",
    "                f\"Train Epoch: {epoch} [{batch_idx * len(data)} / {len(loaders['train'].dataset)} \"\n",
    "                f\"({100. * batch_idx / len(loaders['train']):.0f}%)]\\tLoss: {loss.item():.6f}\"\n",
    "            )\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders[\"test\"]:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders[\"test\"].dataset)\n",
    "    print(\n",
    "        f\"\\nTest set: Average Loss: {test_loss:.4f}, Accuracy: {correct / len(loaders['test'].dataset):.4f} \"\n",
    "        f\"({100. * correct / len(loaders['test'].dataset):.0f}%)\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65a6f889-b16e-4b0c-9d01-a0affc91ead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4068/4166115521.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0 / 60000 (0%)]\tLoss: 2.301594\n",
      "Train Epoch: 1 [2000 / 60000 (3%)]\tLoss: 2.283265\n",
      "Train Epoch: 1 [4000 / 60000 (7%)]\tLoss: 2.206589\n",
      "Train Epoch: 1 [6000 / 60000 (10%)]\tLoss: 2.026017\n",
      "Train Epoch: 1 [8000 / 60000 (13%)]\tLoss: 1.967116\n",
      "Train Epoch: 1 [10000 / 60000 (17%)]\tLoss: 1.877508\n",
      "Train Epoch: 1 [12000 / 60000 (20%)]\tLoss: 1.867585\n",
      "Train Epoch: 1 [14000 / 60000 (23%)]\tLoss: 1.799707\n",
      "Train Epoch: 1 [16000 / 60000 (27%)]\tLoss: 1.767324\n",
      "Train Epoch: 1 [18000 / 60000 (30%)]\tLoss: 1.780973\n",
      "Train Epoch: 1 [20000 / 60000 (33%)]\tLoss: 1.726633\n",
      "Train Epoch: 1 [22000 / 60000 (37%)]\tLoss: 1.695183\n",
      "Train Epoch: 1 [24000 / 60000 (40%)]\tLoss: 1.808055\n",
      "Train Epoch: 1 [26000 / 60000 (43%)]\tLoss: 1.666604\n",
      "Train Epoch: 1 [28000 / 60000 (47%)]\tLoss: 1.735069\n",
      "Train Epoch: 1 [30000 / 60000 (50%)]\tLoss: 1.728507\n",
      "Train Epoch: 1 [32000 / 60000 (53%)]\tLoss: 1.638429\n",
      "Train Epoch: 1 [34000 / 60000 (57%)]\tLoss: 1.726622\n",
      "Train Epoch: 1 [36000 / 60000 (60%)]\tLoss: 1.635756\n",
      "Train Epoch: 1 [38000 / 60000 (63%)]\tLoss: 1.621427\n",
      "Train Epoch: 1 [40000 / 60000 (67%)]\tLoss: 1.681855\n",
      "Train Epoch: 1 [42000 / 60000 (70%)]\tLoss: 1.693875\n",
      "Train Epoch: 1 [44000 / 60000 (73%)]\tLoss: 1.609356\n",
      "Train Epoch: 1 [46000 / 60000 (77%)]\tLoss: 1.649345\n",
      "Train Epoch: 1 [48000 / 60000 (80%)]\tLoss: 1.641943\n",
      "Train Epoch: 1 [50000 / 60000 (83%)]\tLoss: 1.605609\n",
      "Train Epoch: 1 [52000 / 60000 (87%)]\tLoss: 1.558174\n",
      "Train Epoch: 1 [54000 / 60000 (90%)]\tLoss: 1.612591\n",
      "Train Epoch: 1 [56000 / 60000 (93%)]\tLoss: 1.592046\n",
      "Train Epoch: 1 [58000 / 60000 (97%)]\tLoss: 1.661876\n",
      "\n",
      "Test set: Average Loss: 0.0153, Accuracy: 0.9297 (93%)\n",
      "\n",
      "Train Epoch: 2 [0 / 60000 (0%)]\tLoss: 1.611771\n",
      "Train Epoch: 2 [2000 / 60000 (3%)]\tLoss: 1.655899\n",
      "Train Epoch: 2 [4000 / 60000 (7%)]\tLoss: 1.616472\n",
      "Train Epoch: 2 [6000 / 60000 (10%)]\tLoss: 1.557024\n",
      "Train Epoch: 2 [8000 / 60000 (13%)]\tLoss: 1.561630\n",
      "Train Epoch: 2 [10000 / 60000 (17%)]\tLoss: 1.559662\n",
      "Train Epoch: 2 [12000 / 60000 (20%)]\tLoss: 1.574840\n",
      "Train Epoch: 2 [14000 / 60000 (23%)]\tLoss: 1.528878\n",
      "Train Epoch: 2 [16000 / 60000 (27%)]\tLoss: 1.594007\n",
      "Train Epoch: 2 [18000 / 60000 (30%)]\tLoss: 1.581723\n",
      "Train Epoch: 2 [20000 / 60000 (33%)]\tLoss: 1.544456\n",
      "Train Epoch: 2 [22000 / 60000 (37%)]\tLoss: 1.553646\n",
      "Train Epoch: 2 [24000 / 60000 (40%)]\tLoss: 1.577955\n",
      "Train Epoch: 2 [26000 / 60000 (43%)]\tLoss: 1.615814\n",
      "Train Epoch: 2 [28000 / 60000 (47%)]\tLoss: 1.545781\n",
      "Train Epoch: 2 [30000 / 60000 (50%)]\tLoss: 1.607600\n",
      "Train Epoch: 2 [32000 / 60000 (53%)]\tLoss: 1.591531\n",
      "Train Epoch: 2 [34000 / 60000 (57%)]\tLoss: 1.587085\n",
      "Train Epoch: 2 [36000 / 60000 (60%)]\tLoss: 1.571820\n",
      "Train Epoch: 2 [38000 / 60000 (63%)]\tLoss: 1.550902\n",
      "Train Epoch: 2 [40000 / 60000 (67%)]\tLoss: 1.544497\n",
      "Train Epoch: 2 [42000 / 60000 (70%)]\tLoss: 1.570046\n",
      "Train Epoch: 2 [44000 / 60000 (73%)]\tLoss: 1.563736\n",
      "Train Epoch: 2 [46000 / 60000 (77%)]\tLoss: 1.584963\n",
      "Train Epoch: 2 [48000 / 60000 (80%)]\tLoss: 1.534490\n",
      "Train Epoch: 2 [50000 / 60000 (83%)]\tLoss: 1.531363\n",
      "Train Epoch: 2 [52000 / 60000 (87%)]\tLoss: 1.614518\n",
      "Train Epoch: 2 [54000 / 60000 (90%)]\tLoss: 1.561443\n",
      "Train Epoch: 2 [56000 / 60000 (93%)]\tLoss: 1.578352\n",
      "Train Epoch: 2 [58000 / 60000 (97%)]\tLoss: 1.547328\n",
      "\n",
      "Test set: Average Loss: 0.0151, Accuracy: 0.9506 (95%)\n",
      "\n",
      "Train Epoch: 3 [0 / 60000 (0%)]\tLoss: 1.509848\n",
      "Train Epoch: 3 [2000 / 60000 (3%)]\tLoss: 1.634363\n",
      "Train Epoch: 3 [4000 / 60000 (7%)]\tLoss: 1.631315\n",
      "Train Epoch: 3 [6000 / 60000 (10%)]\tLoss: 1.561045\n",
      "Train Epoch: 3 [8000 / 60000 (13%)]\tLoss: 1.602589\n",
      "Train Epoch: 3 [10000 / 60000 (17%)]\tLoss: 1.609050\n",
      "Train Epoch: 3 [12000 / 60000 (20%)]\tLoss: 1.575067\n",
      "Train Epoch: 3 [14000 / 60000 (23%)]\tLoss: 1.566318\n",
      "Train Epoch: 3 [16000 / 60000 (27%)]\tLoss: 1.546177\n",
      "Train Epoch: 3 [18000 / 60000 (30%)]\tLoss: 1.532347\n",
      "Train Epoch: 3 [20000 / 60000 (33%)]\tLoss: 1.546929\n",
      "Train Epoch: 3 [22000 / 60000 (37%)]\tLoss: 1.567887\n",
      "Train Epoch: 3 [24000 / 60000 (40%)]\tLoss: 1.527568\n",
      "Train Epoch: 3 [26000 / 60000 (43%)]\tLoss: 1.560960\n",
      "Train Epoch: 3 [28000 / 60000 (47%)]\tLoss: 1.565393\n",
      "Train Epoch: 3 [30000 / 60000 (50%)]\tLoss: 1.543069\n",
      "Train Epoch: 3 [32000 / 60000 (53%)]\tLoss: 1.651842\n",
      "Train Epoch: 3 [34000 / 60000 (57%)]\tLoss: 1.610776\n",
      "Train Epoch: 3 [36000 / 60000 (60%)]\tLoss: 1.527803\n",
      "Train Epoch: 3 [38000 / 60000 (63%)]\tLoss: 1.604270\n",
      "Train Epoch: 3 [40000 / 60000 (67%)]\tLoss: 1.595510\n",
      "Train Epoch: 3 [42000 / 60000 (70%)]\tLoss: 1.538584\n",
      "Train Epoch: 3 [44000 / 60000 (73%)]\tLoss: 1.596785\n",
      "Train Epoch: 3 [46000 / 60000 (77%)]\tLoss: 1.574247\n",
      "Train Epoch: 3 [48000 / 60000 (80%)]\tLoss: 1.616064\n",
      "Train Epoch: 3 [50000 / 60000 (83%)]\tLoss: 1.562623\n",
      "Train Epoch: 3 [52000 / 60000 (87%)]\tLoss: 1.572943\n",
      "Train Epoch: 3 [54000 / 60000 (90%)]\tLoss: 1.559577\n",
      "Train Epoch: 3 [56000 / 60000 (93%)]\tLoss: 1.543181\n",
      "Train Epoch: 3 [58000 / 60000 (97%)]\tLoss: 1.584655\n",
      "\n",
      "Test set: Average Loss: 0.0150, Accuracy: 0.9574 (96%)\n",
      "\n",
      "Train Epoch: 4 [0 / 60000 (0%)]\tLoss: 1.570605\n",
      "Train Epoch: 4 [2000 / 60000 (3%)]\tLoss: 1.548843\n",
      "Train Epoch: 4 [4000 / 60000 (7%)]\tLoss: 1.555327\n",
      "Train Epoch: 4 [6000 / 60000 (10%)]\tLoss: 1.526792\n",
      "Train Epoch: 4 [8000 / 60000 (13%)]\tLoss: 1.545405\n",
      "Train Epoch: 4 [10000 / 60000 (17%)]\tLoss: 1.591993\n",
      "Train Epoch: 4 [12000 / 60000 (20%)]\tLoss: 1.557104\n",
      "Train Epoch: 4 [14000 / 60000 (23%)]\tLoss: 1.554337\n",
      "Train Epoch: 4 [16000 / 60000 (27%)]\tLoss: 1.542549\n",
      "Train Epoch: 4 [18000 / 60000 (30%)]\tLoss: 1.574766\n",
      "Train Epoch: 4 [20000 / 60000 (33%)]\tLoss: 1.520664\n",
      "Train Epoch: 4 [22000 / 60000 (37%)]\tLoss: 1.600232\n",
      "Train Epoch: 4 [24000 / 60000 (40%)]\tLoss: 1.601573\n",
      "Train Epoch: 4 [26000 / 60000 (43%)]\tLoss: 1.524189\n",
      "Train Epoch: 4 [28000 / 60000 (47%)]\tLoss: 1.585189\n",
      "Train Epoch: 4 [30000 / 60000 (50%)]\tLoss: 1.583291\n",
      "Train Epoch: 4 [32000 / 60000 (53%)]\tLoss: 1.568192\n",
      "Train Epoch: 4 [34000 / 60000 (57%)]\tLoss: 1.542592\n",
      "Train Epoch: 4 [36000 / 60000 (60%)]\tLoss: 1.543816\n",
      "Train Epoch: 4 [38000 / 60000 (63%)]\tLoss: 1.541613\n",
      "Train Epoch: 4 [40000 / 60000 (67%)]\tLoss: 1.592991\n",
      "Train Epoch: 4 [42000 / 60000 (70%)]\tLoss: 1.562690\n",
      "Train Epoch: 4 [44000 / 60000 (73%)]\tLoss: 1.568177\n",
      "Train Epoch: 4 [46000 / 60000 (77%)]\tLoss: 1.572432\n",
      "Train Epoch: 4 [48000 / 60000 (80%)]\tLoss: 1.514963\n",
      "Train Epoch: 4 [50000 / 60000 (83%)]\tLoss: 1.579224\n",
      "Train Epoch: 4 [52000 / 60000 (87%)]\tLoss: 1.561010\n",
      "Train Epoch: 4 [54000 / 60000 (90%)]\tLoss: 1.609836\n",
      "Train Epoch: 4 [56000 / 60000 (93%)]\tLoss: 1.543795\n",
      "Train Epoch: 4 [58000 / 60000 (97%)]\tLoss: 1.577863\n",
      "\n",
      "Test set: Average Loss: 0.0150, Accuracy: 0.9612 (96%)\n",
      "\n",
      "Train Epoch: 5 [0 / 60000 (0%)]\tLoss: 1.576316\n",
      "Train Epoch: 5 [2000 / 60000 (3%)]\tLoss: 1.546737\n",
      "Train Epoch: 5 [4000 / 60000 (7%)]\tLoss: 1.530288\n",
      "Train Epoch: 5 [6000 / 60000 (10%)]\tLoss: 1.570239\n",
      "Train Epoch: 5 [8000 / 60000 (13%)]\tLoss: 1.558957\n",
      "Train Epoch: 5 [10000 / 60000 (17%)]\tLoss: 1.520087\n",
      "Train Epoch: 5 [12000 / 60000 (20%)]\tLoss: 1.585631\n",
      "Train Epoch: 5 [14000 / 60000 (23%)]\tLoss: 1.535660\n",
      "Train Epoch: 5 [16000 / 60000 (27%)]\tLoss: 1.537454\n",
      "Train Epoch: 5 [18000 / 60000 (30%)]\tLoss: 1.525633\n",
      "Train Epoch: 5 [20000 / 60000 (33%)]\tLoss: 1.538390\n",
      "Train Epoch: 5 [22000 / 60000 (37%)]\tLoss: 1.522033\n",
      "Train Epoch: 5 [24000 / 60000 (40%)]\tLoss: 1.569472\n",
      "Train Epoch: 5 [26000 / 60000 (43%)]\tLoss: 1.580451\n",
      "Train Epoch: 5 [28000 / 60000 (47%)]\tLoss: 1.528129\n",
      "Train Epoch: 5 [30000 / 60000 (50%)]\tLoss: 1.597092\n",
      "Train Epoch: 5 [32000 / 60000 (53%)]\tLoss: 1.584261\n",
      "Train Epoch: 5 [34000 / 60000 (57%)]\tLoss: 1.519048\n",
      "Train Epoch: 5 [36000 / 60000 (60%)]\tLoss: 1.587863\n",
      "Train Epoch: 5 [38000 / 60000 (63%)]\tLoss: 1.506356\n",
      "Train Epoch: 5 [40000 / 60000 (67%)]\tLoss: 1.494875\n",
      "Train Epoch: 5 [42000 / 60000 (70%)]\tLoss: 1.525207\n",
      "Train Epoch: 5 [44000 / 60000 (73%)]\tLoss: 1.575328\n",
      "Train Epoch: 5 [46000 / 60000 (77%)]\tLoss: 1.546371\n",
      "Train Epoch: 5 [48000 / 60000 (80%)]\tLoss: 1.583289\n",
      "Train Epoch: 5 [50000 / 60000 (83%)]\tLoss: 1.506704\n",
      "Train Epoch: 5 [52000 / 60000 (87%)]\tLoss: 1.514802\n",
      "Train Epoch: 5 [54000 / 60000 (90%)]\tLoss: 1.557433\n",
      "Train Epoch: 5 [56000 / 60000 (93%)]\tLoss: 1.551307\n",
      "Train Epoch: 5 [58000 / 60000 (97%)]\tLoss: 1.516690\n",
      "\n",
      "Test set: Average Loss: 0.0150, Accuracy: 0.9661 (97%)\n",
      "\n",
      "Train Epoch: 6 [0 / 60000 (0%)]\tLoss: 1.518598\n",
      "Train Epoch: 6 [2000 / 60000 (3%)]\tLoss: 1.522338\n",
      "Train Epoch: 6 [4000 / 60000 (7%)]\tLoss: 1.553093\n",
      "Train Epoch: 6 [6000 / 60000 (10%)]\tLoss: 1.562611\n",
      "Train Epoch: 6 [8000 / 60000 (13%)]\tLoss: 1.547986\n",
      "Train Epoch: 6 [10000 / 60000 (17%)]\tLoss: 1.550362\n",
      "Train Epoch: 6 [12000 / 60000 (20%)]\tLoss: 1.587548\n",
      "Train Epoch: 6 [14000 / 60000 (23%)]\tLoss: 1.571120\n",
      "Train Epoch: 6 [16000 / 60000 (27%)]\tLoss: 1.556416\n",
      "Train Epoch: 6 [18000 / 60000 (30%)]\tLoss: 1.546175\n",
      "Train Epoch: 6 [20000 / 60000 (33%)]\tLoss: 1.513143\n",
      "Train Epoch: 6 [22000 / 60000 (37%)]\tLoss: 1.565832\n",
      "Train Epoch: 6 [24000 / 60000 (40%)]\tLoss: 1.510616\n",
      "Train Epoch: 6 [26000 / 60000 (43%)]\tLoss: 1.519131\n",
      "Train Epoch: 6 [28000 / 60000 (47%)]\tLoss: 1.528545\n",
      "Train Epoch: 6 [30000 / 60000 (50%)]\tLoss: 1.526236\n",
      "Train Epoch: 6 [32000 / 60000 (53%)]\tLoss: 1.558293\n",
      "Train Epoch: 6 [34000 / 60000 (57%)]\tLoss: 1.572321\n",
      "Train Epoch: 6 [36000 / 60000 (60%)]\tLoss: 1.542405\n",
      "Train Epoch: 6 [38000 / 60000 (63%)]\tLoss: 1.580347\n",
      "Train Epoch: 6 [40000 / 60000 (67%)]\tLoss: 1.571899\n",
      "Train Epoch: 6 [42000 / 60000 (70%)]\tLoss: 1.509227\n",
      "Train Epoch: 6 [44000 / 60000 (73%)]\tLoss: 1.528466\n",
      "Train Epoch: 6 [46000 / 60000 (77%)]\tLoss: 1.538937\n",
      "Train Epoch: 6 [48000 / 60000 (80%)]\tLoss: 1.492862\n",
      "Train Epoch: 6 [50000 / 60000 (83%)]\tLoss: 1.536420\n",
      "Train Epoch: 6 [52000 / 60000 (87%)]\tLoss: 1.519917\n",
      "Train Epoch: 6 [54000 / 60000 (90%)]\tLoss: 1.568355\n",
      "Train Epoch: 6 [56000 / 60000 (93%)]\tLoss: 1.524598\n",
      "Train Epoch: 6 [58000 / 60000 (97%)]\tLoss: 1.576390\n",
      "\n",
      "Test set: Average Loss: 0.0150, Accuracy: 0.9665 (97%)\n",
      "\n",
      "Train Epoch: 7 [0 / 60000 (0%)]\tLoss: 1.530846\n",
      "Train Epoch: 7 [2000 / 60000 (3%)]\tLoss: 1.554243\n",
      "Train Epoch: 7 [4000 / 60000 (7%)]\tLoss: 1.545667\n",
      "Train Epoch: 7 [6000 / 60000 (10%)]\tLoss: 1.549089\n",
      "Train Epoch: 7 [8000 / 60000 (13%)]\tLoss: 1.503016\n",
      "Train Epoch: 7 [10000 / 60000 (17%)]\tLoss: 1.532786\n",
      "Train Epoch: 7 [12000 / 60000 (20%)]\tLoss: 1.532703\n",
      "Train Epoch: 7 [14000 / 60000 (23%)]\tLoss: 1.586439\n",
      "Train Epoch: 7 [16000 / 60000 (27%)]\tLoss: 1.519321\n",
      "Train Epoch: 7 [18000 / 60000 (30%)]\tLoss: 1.493805\n",
      "Train Epoch: 7 [20000 / 60000 (33%)]\tLoss: 1.562083\n",
      "Train Epoch: 7 [22000 / 60000 (37%)]\tLoss: 1.496912\n",
      "Train Epoch: 7 [24000 / 60000 (40%)]\tLoss: 1.495233\n",
      "Train Epoch: 7 [26000 / 60000 (43%)]\tLoss: 1.551295\n",
      "Train Epoch: 7 [28000 / 60000 (47%)]\tLoss: 1.517349\n",
      "Train Epoch: 7 [30000 / 60000 (50%)]\tLoss: 1.546021\n",
      "Train Epoch: 7 [32000 / 60000 (53%)]\tLoss: 1.546299\n",
      "Train Epoch: 7 [34000 / 60000 (57%)]\tLoss: 1.538676\n",
      "Train Epoch: 7 [36000 / 60000 (60%)]\tLoss: 1.504432\n",
      "Train Epoch: 7 [38000 / 60000 (63%)]\tLoss: 1.549261\n",
      "Train Epoch: 7 [40000 / 60000 (67%)]\tLoss: 1.492499\n",
      "Train Epoch: 7 [42000 / 60000 (70%)]\tLoss: 1.482642\n",
      "Train Epoch: 7 [44000 / 60000 (73%)]\tLoss: 1.544234\n",
      "Train Epoch: 7 [46000 / 60000 (77%)]\tLoss: 1.547332\n",
      "Train Epoch: 7 [48000 / 60000 (80%)]\tLoss: 1.531084\n",
      "Train Epoch: 7 [50000 / 60000 (83%)]\tLoss: 1.508611\n",
      "Train Epoch: 7 [52000 / 60000 (87%)]\tLoss: 1.562224\n",
      "Train Epoch: 7 [54000 / 60000 (90%)]\tLoss: 1.511118\n",
      "Train Epoch: 7 [56000 / 60000 (93%)]\tLoss: 1.561310\n",
      "Train Epoch: 7 [58000 / 60000 (97%)]\tLoss: 1.559371\n",
      "\n",
      "Test set: Average Loss: 0.0149, Accuracy: 0.9681 (97%)\n",
      "\n",
      "Train Epoch: 8 [0 / 60000 (0%)]\tLoss: 1.558310\n",
      "Train Epoch: 8 [2000 / 60000 (3%)]\tLoss: 1.554170\n",
      "Train Epoch: 8 [4000 / 60000 (7%)]\tLoss: 1.568999\n",
      "Train Epoch: 8 [6000 / 60000 (10%)]\tLoss: 1.605593\n",
      "Train Epoch: 8 [8000 / 60000 (13%)]\tLoss: 1.538437\n",
      "Train Epoch: 8 [10000 / 60000 (17%)]\tLoss: 1.531361\n",
      "Train Epoch: 8 [12000 / 60000 (20%)]\tLoss: 1.564435\n",
      "Train Epoch: 8 [14000 / 60000 (23%)]\tLoss: 1.507140\n",
      "Train Epoch: 8 [16000 / 60000 (27%)]\tLoss: 1.528241\n",
      "Train Epoch: 8 [18000 / 60000 (30%)]\tLoss: 1.540026\n",
      "Train Epoch: 8 [20000 / 60000 (33%)]\tLoss: 1.530560\n",
      "Train Epoch: 8 [22000 / 60000 (37%)]\tLoss: 1.564164\n",
      "Train Epoch: 8 [24000 / 60000 (40%)]\tLoss: 1.538067\n",
      "Train Epoch: 8 [26000 / 60000 (43%)]\tLoss: 1.504718\n",
      "Train Epoch: 8 [28000 / 60000 (47%)]\tLoss: 1.526515\n",
      "Train Epoch: 8 [30000 / 60000 (50%)]\tLoss: 1.554009\n",
      "Train Epoch: 8 [32000 / 60000 (53%)]\tLoss: 1.551786\n",
      "Train Epoch: 8 [34000 / 60000 (57%)]\tLoss: 1.515652\n",
      "Train Epoch: 8 [36000 / 60000 (60%)]\tLoss: 1.517008\n",
      "Train Epoch: 8 [38000 / 60000 (63%)]\tLoss: 1.518614\n",
      "Train Epoch: 8 [40000 / 60000 (67%)]\tLoss: 1.549737\n",
      "Train Epoch: 8 [42000 / 60000 (70%)]\tLoss: 1.527319\n",
      "Train Epoch: 8 [44000 / 60000 (73%)]\tLoss: 1.528341\n",
      "Train Epoch: 8 [46000 / 60000 (77%)]\tLoss: 1.535653\n",
      "Train Epoch: 8 [48000 / 60000 (80%)]\tLoss: 1.511108\n",
      "Train Epoch: 8 [50000 / 60000 (83%)]\tLoss: 1.489364\n",
      "Train Epoch: 8 [52000 / 60000 (87%)]\tLoss: 1.499745\n",
      "Train Epoch: 8 [54000 / 60000 (90%)]\tLoss: 1.527196\n",
      "Train Epoch: 8 [56000 / 60000 (93%)]\tLoss: 1.534159\n",
      "Train Epoch: 8 [58000 / 60000 (97%)]\tLoss: 1.553056\n",
      "\n",
      "Test set: Average Loss: 0.0149, Accuracy: 0.9701 (97%)\n",
      "\n",
      "Train Epoch: 9 [0 / 60000 (0%)]\tLoss: 1.527204\n",
      "Train Epoch: 9 [2000 / 60000 (3%)]\tLoss: 1.518165\n",
      "Train Epoch: 9 [4000 / 60000 (7%)]\tLoss: 1.538987\n",
      "Train Epoch: 9 [6000 / 60000 (10%)]\tLoss: 1.562757\n",
      "Train Epoch: 9 [8000 / 60000 (13%)]\tLoss: 1.526443\n",
      "Train Epoch: 9 [10000 / 60000 (17%)]\tLoss: 1.521008\n",
      "Train Epoch: 9 [12000 / 60000 (20%)]\tLoss: 1.531711\n",
      "Train Epoch: 9 [14000 / 60000 (23%)]\tLoss: 1.522073\n",
      "Train Epoch: 9 [16000 / 60000 (27%)]\tLoss: 1.536682\n",
      "Train Epoch: 9 [18000 / 60000 (30%)]\tLoss: 1.525461\n",
      "Train Epoch: 9 [20000 / 60000 (33%)]\tLoss: 1.532155\n",
      "Train Epoch: 9 [22000 / 60000 (37%)]\tLoss: 1.522401\n",
      "Train Epoch: 9 [24000 / 60000 (40%)]\tLoss: 1.491148\n",
      "Train Epoch: 9 [26000 / 60000 (43%)]\tLoss: 1.491228\n",
      "Train Epoch: 9 [28000 / 60000 (47%)]\tLoss: 1.517511\n",
      "Train Epoch: 9 [30000 / 60000 (50%)]\tLoss: 1.534439\n",
      "Train Epoch: 9 [32000 / 60000 (53%)]\tLoss: 1.516276\n",
      "Train Epoch: 9 [34000 / 60000 (57%)]\tLoss: 1.540611\n",
      "Train Epoch: 9 [36000 / 60000 (60%)]\tLoss: 1.491490\n",
      "Train Epoch: 9 [38000 / 60000 (63%)]\tLoss: 1.513490\n",
      "Train Epoch: 9 [40000 / 60000 (67%)]\tLoss: 1.547955\n",
      "Train Epoch: 9 [42000 / 60000 (70%)]\tLoss: 1.490031\n",
      "Train Epoch: 9 [44000 / 60000 (73%)]\tLoss: 1.552743\n",
      "Train Epoch: 9 [46000 / 60000 (77%)]\tLoss: 1.505261\n",
      "Train Epoch: 9 [48000 / 60000 (80%)]\tLoss: 1.508795\n",
      "Train Epoch: 9 [50000 / 60000 (83%)]\tLoss: 1.536477\n",
      "Train Epoch: 9 [52000 / 60000 (87%)]\tLoss: 1.577187\n",
      "Train Epoch: 9 [54000 / 60000 (90%)]\tLoss: 1.510043\n",
      "Train Epoch: 9 [56000 / 60000 (93%)]\tLoss: 1.556281\n",
      "Train Epoch: 9 [58000 / 60000 (97%)]\tLoss: 1.544011\n",
      "\n",
      "Test set: Average Loss: 0.0149, Accuracy: 0.9703 (97%)\n",
      "\n",
      "Train Epoch: 10 [0 / 60000 (0%)]\tLoss: 1.520612\n",
      "Train Epoch: 10 [2000 / 60000 (3%)]\tLoss: 1.541499\n",
      "Train Epoch: 10 [4000 / 60000 (7%)]\tLoss: 1.527211\n",
      "Train Epoch: 10 [6000 / 60000 (10%)]\tLoss: 1.523914\n",
      "Train Epoch: 10 [8000 / 60000 (13%)]\tLoss: 1.517068\n",
      "Train Epoch: 10 [10000 / 60000 (17%)]\tLoss: 1.523666\n",
      "Train Epoch: 10 [12000 / 60000 (20%)]\tLoss: 1.503684\n",
      "Train Epoch: 10 [14000 / 60000 (23%)]\tLoss: 1.523965\n",
      "Train Epoch: 10 [16000 / 60000 (27%)]\tLoss: 1.558261\n",
      "Train Epoch: 10 [18000 / 60000 (30%)]\tLoss: 1.507586\n",
      "Train Epoch: 10 [20000 / 60000 (33%)]\tLoss: 1.514573\n",
      "Train Epoch: 10 [22000 / 60000 (37%)]\tLoss: 1.532839\n",
      "Train Epoch: 10 [24000 / 60000 (40%)]\tLoss: 1.573536\n",
      "Train Epoch: 10 [26000 / 60000 (43%)]\tLoss: 1.557290\n",
      "Train Epoch: 10 [28000 / 60000 (47%)]\tLoss: 1.485683\n",
      "Train Epoch: 10 [30000 / 60000 (50%)]\tLoss: 1.545939\n",
      "Train Epoch: 10 [32000 / 60000 (53%)]\tLoss: 1.494450\n",
      "Train Epoch: 10 [34000 / 60000 (57%)]\tLoss: 1.530933\n",
      "Train Epoch: 10 [36000 / 60000 (60%)]\tLoss: 1.532994\n",
      "Train Epoch: 10 [38000 / 60000 (63%)]\tLoss: 1.521632\n",
      "Train Epoch: 10 [40000 / 60000 (67%)]\tLoss: 1.538854\n",
      "Train Epoch: 10 [42000 / 60000 (70%)]\tLoss: 1.471667\n",
      "Train Epoch: 10 [44000 / 60000 (73%)]\tLoss: 1.494965\n",
      "Train Epoch: 10 [46000 / 60000 (77%)]\tLoss: 1.522204\n",
      "Train Epoch: 10 [48000 / 60000 (80%)]\tLoss: 1.551139\n",
      "Train Epoch: 10 [50000 / 60000 (83%)]\tLoss: 1.538083\n",
      "Train Epoch: 10 [52000 / 60000 (87%)]\tLoss: 1.524706\n",
      "Train Epoch: 10 [54000 / 60000 (90%)]\tLoss: 1.536849\n",
      "Train Epoch: 10 [56000 / 60000 (93%)]\tLoss: 1.530759\n",
      "Train Epoch: 10 [58000 / 60000 (97%)]\tLoss: 1.547149\n",
      "\n",
      "Test set: Average Loss: 0.0149, Accuracy: 0.9738 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3154a172-21c6-4fb1-9266-e8f52b6c005b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e417165-730e-44b0-943f-ac2e8b050185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4068/4166115521.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[1]  \n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f'Prediction: {prediction}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c3f89-e39f-40ce-b7f7-64465d4844c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d62d0d2-7988-4d65-acb0-d759db07098b",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "1. https://www.youtube.com/watch?v=vBlO87ZAiiw. NeuralNine. PyTorch Project: Handwritten Digit Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455b5f8-6149-4928-96a3-6020fc08d083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef44e54-222f-474d-b67e-023f55486d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
